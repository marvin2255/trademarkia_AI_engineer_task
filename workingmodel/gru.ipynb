{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e435f6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28f95ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load and preprocess the training data\n",
    "with open('traindata (2).json') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "# Remove unwanted classes from the training dataset\n",
    "unwanted_classes = ['000', '200', 'B','A']\n",
    "train_data = {key: value for key, value in train_data.items() if key not in unwanted_classes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a9df0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the training data\n",
    "train_texts = []\n",
    "train_labels = []\n",
    "for key, values in train_data.items():\n",
    "    train_texts.extend(values)\n",
    "    train_labels.extend([key] * len(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60cecb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load and preprocess the testing data\n",
    "with open('testdata (2).json') as f:\n",
    "    test_data = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66f6bc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unwanted classes from the testing dataset\n",
    "test_data = {key: value for key, value in test_data.items() if key not in unwanted_classes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19a18f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the testing data\n",
    "test_texts = []\n",
    "test_labels = []\n",
    "for key, values in test_data.items():\n",
    "    test_texts.extend(values)\n",
    "    test_labels.extend([key] * len(values))\n",
    "\n",
    "# Step 3: Preprocess the text data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_texts)\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
    "\n",
    "max_sequence_length = max(len(sequence) for sequence in train_sequences)\n",
    "train_padded = pad_sequences(train_sequences, maxlen=max_sequence_length)\n",
    "test_padded = pad_sequences(test_sequences, maxlen=max_sequence_length)\n",
    "\n",
    "label_to_id = {label: idx for idx, label in enumerate(set(train_labels))}\n",
    "train_encoded = np.array([label_to_id[label] for label in train_labels])\n",
    "test_encoded = np.array([label_to_id[label] for label in test_labels])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06bc21c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Build the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_sequence_length))\n",
    "model.add(GRU(units=128))\n",
    "model.add(Dense(units=len(label_to_id), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b118def6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1650/1650 [==============================] - 118s 71ms/step - loss: 1.6627 - accuracy: 0.5571\n",
      "Epoch 2/10\n",
      "1650/1650 [==============================] - 120s 73ms/step - loss: 0.4974 - accuracy: 0.8650\n",
      "Epoch 3/10\n",
      "1650/1650 [==============================] - 120s 73ms/step - loss: 0.2299 - accuracy: 0.9360\n",
      "Epoch 4/10\n",
      "1650/1650 [==============================] - 121s 73ms/step - loss: 0.1336 - accuracy: 0.9614\n",
      "Epoch 5/10\n",
      "1650/1650 [==============================] - 116s 70ms/step - loss: 0.0895 - accuracy: 0.9743\n",
      "Epoch 6/10\n",
      "1650/1650 [==============================] - 117s 71ms/step - loss: 0.0645 - accuracy: 0.9810\n",
      "Epoch 7/10\n",
      "1650/1650 [==============================] - 115s 70ms/step - loss: 0.0466 - accuracy: 0.9869\n",
      "Epoch 8/10\n",
      "1650/1650 [==============================] - 115s 70ms/step - loss: 0.0360 - accuracy: 0.9903\n",
      "Epoch 9/10\n",
      "1650/1650 [==============================] - 114s 69ms/step - loss: 0.0297 - accuracy: 0.9915\n",
      "Epoch 10/10\n",
      "1650/1650 [==============================] - 115s 70ms/step - loss: 0.0257 - accuracy: 0.9926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24dac1ccd90>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5: Compile and train the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(train_padded, train_encoded, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ba48b837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Save the trained model\n",
    "model.save('gru_model.h5')\n",
    "print('Model saved successfully.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "09de610d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Load the saved model\n",
    "loaded_model = load_model('gru_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "96aae76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 3s 13ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         011       0.78      0.77      0.77       172\n",
      "         013       0.84      0.66      0.74        41\n",
      "         021       0.83      0.72      0.77       211\n",
      "         028       0.86      0.87      0.86       211\n",
      "         010       0.88      0.86      0.87       185\n",
      "         005       0.90      0.81      0.85       211\n",
      "         043       0.92      0.82      0.87        55\n",
      "         033       0.89      0.78      0.83        32\n",
      "         025       0.88      0.75      0.81       142\n",
      "         037       0.93      0.92      0.93       249\n",
      "         020       0.76      0.76      0.76       157\n",
      "         022       0.65      0.62      0.63        42\n",
      "         039       0.81      0.86      0.84        77\n",
      "         024       0.84      0.82      0.83        62\n",
      "         007       0.82      0.89      0.85       233\n",
      "         034       0.91      0.97      0.94        31\n",
      "         027       0.92      0.96      0.94        23\n",
      "         008       0.87      0.83      0.85       100\n",
      "         016       0.88      0.90      0.89       288\n",
      "         045       0.87      0.69      0.77        86\n",
      "         026       0.80      0.77      0.79        57\n",
      "         004       0.78      0.87      0.82        52\n",
      "         018       0.84      0.78      0.81        80\n",
      "         015       0.79      0.79      0.79        39\n",
      "         030       0.86      0.73      0.79       178\n",
      "         036       0.93      0.86      0.90       115\n",
      "         003       0.79      0.90      0.84       159\n",
      "         038       0.81      0.90      0.85        52\n",
      "         019       0.80      0.76      0.78       117\n",
      "         017       0.74      0.62      0.68        77\n",
      "         044       0.82      0.85      0.83       121\n",
      "         035       0.93      0.88      0.90       245\n",
      "         014       0.85      0.79      0.82        57\n",
      "         002       0.89      0.84      0.86        61\n",
      "         012       0.85      0.86      0.86       155\n",
      "         032       0.87      0.88      0.87        51\n",
      "         042       0.88      0.88      0.88       190\n",
      "         029       0.49      0.81      0.61       170\n",
      "         006       0.86      0.94      0.90       163\n",
      "         001       0.83      0.74      0.78       210\n",
      "         031       0.78      0.92      0.85        87\n",
      "         009       0.87      0.86      0.86       546\n",
      "         041       0.90      0.91      0.91       197\n",
      "         023       0.88      1.00      0.93        14\n",
      "         040       0.76      0.83      0.79        89\n",
      "\n",
      "    accuracy                           0.83      5890\n",
      "   macro avg       0.84      0.83      0.83      5890\n",
      "weighted avg       0.84      0.83      0.84      5890\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Generate classification report\n",
    "test_predictions = loaded_model.predict(test_padded)\n",
    "test_predictions = np.argmax(test_predictions, axis=1)\n",
    "target_names = list(label_to_id.keys())\n",
    "classification_report_output = classification_report(test_encoded, test_predictions, target_names=target_names)\n",
    "print('Classification Report:')\n",
    "print(classification_report_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9996a0e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a sentence (or 'exit' to quit): chicken fry brand\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Predicted class: 029\n"
     ]
    }
   ],
   "source": [
    "# Step 10: Predict the class from user input using the loaded model\n",
    "while True:\n",
    "    user_input = input(\"Enter a sentence (or 'exit' to quit): \")\n",
    "    if user_input.lower() == 'exit':\n",
    "        break\n",
    "\n",
    "    # Preprocess the user input\n",
    "    user_sequence = tokenizer.texts_to_sequences([user_input])\n",
    "    user_padded = pad_sequences(user_sequence, maxlen=max_sequence_length)\n",
    "\n",
    "    # Make predictions using the loaded model\n",
    "    user_prediction = loaded_model.predict(user_padded)\n",
    "    user_prediction = np.argmax(user_prediction, axis=1)[0]\n",
    "\n",
    "    # Convert the predicted class index back to the label\n",
    "    id_to_label = {v: k for k, v in label_to_id.items()}\n",
    "    predicted_label = id_to_label[user_prediction]\n",
    "\n",
    "    print('Predicted class:', predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d427867c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
